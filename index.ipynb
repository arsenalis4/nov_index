{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인용문 개수: 45\n",
      "키워드 개수: 45\n"
     ]
    }
   ],
   "source": [
    "# 빅카인즈 api를 활용해서 \"메타버스\" 뉴스의 인용문과 키워드를 출력하는 파이썬 코드\n",
    "\n",
    "# 필요한 모듈 임포트\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 빅카인즈 api 키와 url 설정\n",
    "api_key = \"830f5a0b-192a-44ee-9066-ef174c732aa1\"\n",
    "quotation_url = \"http://tools.kinds.or.kr:8888/search/quotation\"\n",
    "keyword_url = \"http://tools.kinds.or.kr:8888/search/news\"\n",
    "\n",
    "# 검색 조건 설정\n",
    "params = {\n",
    "    \"access_key\": api_key,\n",
    "    \"argument\": {\n",
    "        \"query\": \"메타버스\", # 검색어\n",
    "        \"published_at\": { # 기간\n",
    "            \"from\": \"2022-01-01\",\n",
    "            \"until\": \"2022-12-31\"\n",
    "        },\n",
    "        \"provider\": [], # 언론사\n",
    "        \"category\": [], # 분야\n",
    "        \"category_incident\": [], # 사건/사고 분류\n",
    "        \"byline\": \"\", # 기자\n",
    "        \"provider_subject\": [\"\"], # 주제\n",
    "        \"subject_info\": [\"\"], # 주제어\n",
    "        \"subject_info1\": [\"\"], # 주제어(인물)\n",
    "        \"subject_info2\": [\"\"], # 주제어(지역)\n",
    "        \"subject_info3\": [\"\"], # 주제어(기관)\n",
    "        \"subject_info4\": [\"\"], # 주제어(사건/사고)\n",
    "        \"sort\": {\"date\": \"desc\"}, # 정렬 방식\n",
    "        \"hilight\": 200, # 하이라이트 설정\n",
    "        \"return_from\": 0, # 검색 시작 위치\n",
    "        \"return_size\": 50, # 검색 결과 개수\n",
    "        \"fields\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# api 요청 및 응답 받기\n",
    "quotation_response = requests.post(quotation_url, data=json.dumps(params))\n",
    "quotation_data = quotation_response.json()\n",
    "quotation_documents = quotation_data[\"return_object\"][\"documents\"]\n",
    "\n",
    "keyword_response = requests.post(keyword_url, data=json.dumps(params))\n",
    "keyword_data = keyword_response.json()\n",
    "keyword_documents = keyword_data[\"return_object\"][\"documents\"]\n",
    "\n",
    "# 응답 데이터에서 뉴스 인용문과 키워드 추출\n",
    "quotes = []\n",
    "keywords = []\n",
    "for i in quotation_documents:\n",
    "  quotes.append(i[\"quotation\"])\n",
    "\n",
    "for j in keyword_documents:\n",
    "  keywords.append(j[\"title\"])\n",
    "\n",
    "# 인용문과 키워드 출력\n",
    "print(\"인용문 개수:\", len(quotes))\n",
    "print(\"키워드 개수:\", len(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 인용문 개수: 45\n",
      "전처리된 키워드 개수: 45\n"
     ]
    }
   ],
   "source": [
    "# 수집된 텍스트 데이터를 전처리하여 불필요한 문자, 공백 등을 제거하고, 형태소 분석에 필요한 데이터만 추출\n",
    "import re\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def preprocess(text):\n",
    "    # 불필요한 문자 제거\n",
    "    text = re.sub(r\"[^가-힣A-Za-z0-9 ]\", \"\", text)\n",
    "    # 공백 제거\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # 양쪽 공백 제거\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# 전처리된 인용문과 키워드 리스트 생성\n",
    "preprocessed_quotes = []\n",
    "preprocessed_keywords = []\n",
    "\n",
    "for quote in quotes:\n",
    "    preprocessed_quotes.append(preprocess(quote))\n",
    "\n",
    "for keyword in keywords:\n",
    "    preprocessed_keywords.append(preprocess(keyword))\n",
    "\n",
    "# 전처리된 인용문과 키워드 출력\n",
    "print(\"전처리된 인용문 개수:\", len(preprocessed_quotes))\n",
    "print(\"전처리된 키워드 개수:\", len(preprocessed_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okt 인용문 개수: 45\n",
      "Okt 키워드 개수: 45\n"
     ]
    }
   ],
   "source": [
    "# 추출된 데이터에 대해 형태소 분석기를 적용하여, 단어를 형태소 단위로 분리하고, 각 형태소에 대한 품사 태그를 부착\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# 형태소 분석기 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 형태소 분석 결과를 저장할 리스트 생성\n",
    "okt_quotes = []\n",
    "okt_keywords = []\n",
    "\n",
    "# 인용문에 대해 형태소 분석 수행\n",
    "for quote in preprocessed_quotes:\n",
    "    okt_quotes.append(okt.pos(quote))\n",
    "\n",
    "# 키워드에 대해 형태소 분석 수행\n",
    "for keyword in preprocessed_keywords:\n",
    "    okt_keywords.append(okt.pos(keyword))\n",
    "\n",
    "# 형태소 분석 결과 출력\n",
    "print(\"Okt 인용문 개수:\", len(okt_quotes))\n",
    "print(\"Okt 키워드 개수:\", len(okt_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okt 인용문 형태소 개수: 45\n",
      "Okt 인용문 형태소: [['NFT', 'Nassau', 'NFT', 'PARARIUM', 'MZ', 'M', '2', 'EMove', 'to', 'Earn', 'MOU', '50', 'KFA', '1971', 'MZ', 'MZ', '3', '2021', '10', 'NFT', 'A', 'MBN', 'LG', '2', '3', '3'], ['oVice', 'NextRise', '2023', '1', '2', '5', '5', '450', 'ICT', '9', '400', 'LG', 'CNS', 'SK', 'G', '4000', '11'], ['20', 'there', '2023', '3', '25', '8', '16', '9', '37', '2', '1900', '20', '300', 'OASIS', 'RISES', 'GPT'], ['AFWP', '12', 'ip', '1050', '2022', 'CES', 'KIST', 'Pet', 'Face', 'ID', 'AFWP', '2021', '11', '2022', '8', 'Deep', 'tech', '2023', '5', '900', 'AFWP', 'IP'], ['SOULX', '7', '9', 'COMMUNIC', 'ASIA', '2023', 'ICT', '4', 'UFUI', 'KOTRA', 'XROOM', '3', 'D', '2', 'D', 'UIUX', 'DragampDrop', '1', 'MCN', 'IP', '1', 'CES', '2023', 'Company', 'Visit'], ['tripbtoz', 'VFX', 'SORI', '30', '3', 'D', '5', '12', '5', '1', '5', '2', 'VFX', '3'], ['AI', 'AI', 'MOU', '13', 'MOU', 'SaaS', '2', 'D', '3', 'D', 'OOBC', 'AI', 'AI', 'AI', 'AI', 'AI'], ['20', 'there', '2023', '21', '3', '25', '8', '16', '9', '37', '2', '1900', '20', '300', 'OASIS', 'RISES', 'GPT', 'VRM', '15', '3', '3', '6', '8', '16', '500'], ['7', '9', 'ATxSGAsia', 'Tech', 'x', 'Singapore', '2023', 'ICT', 'XR', 'ATxSGAsia', 'Tech', 'x', 'Singapore', '2023', 'IMDA', 'Infocomm', 'Media', 'Development', 'Authority', 'IT', 'AI', 'IoT', '5', 'G', 'IT', 'UFI', 'XR', '8', '17', '21000', '47', 'chars'], ['ZEMIVERSE', 'Nextor', 'Inc', '415', '27', 'ISTN', '2', 'ZEMIVERSE', 'ZEMIVERSE', '2002', '50', '10', 'MMORPG', '15', '6', '14', '16', 'ZEMIVERSE', 'O', '2', 'O', 'ZEMIVERSE', '3', 'D', 'ZEMI', 'Studio', 'ZEMI', 'Builder', 'A', 'A'], ['tdtd'], ['tdtd'], ['tdtd'], ['LG', 'KidsTopia', 'AIArtificial', 'Intelligence', 'LG'], ['NIPA', '2023', '2030', '1600', 'EU', '2019', '1760', '10', 'OECD', '368', '1', '50', '2023', '6', '2024', '12', 'TOGATHER', 'To', 'Gather', 'Together'], ['tdtd'], ['tdtd'], ['Platum', 'is', 'a', 'media', 'service', 'that', 'specializes', 'in', 'startups', 'and', 'its', 'motto', 'is', 'Startups', 'Story', 'PlatformPlatum', 'means', 'Space', 'for', 'sharing', 'wisdom', 'Plat', 'um', 'we', 'aim', 'to', 'serve', 'as', 'a', 'friendly', 'vertical', 'media', '329', 'chars'], ['Platum', 'is', 'a', 'media', 'service', 'that', 'specializes', 'in', 'startups', 'and', 'its', 'motto', 'is', 'Startups', 'Story', 'PlatformPlatum', 'means', 'Space', 'for', 'sharing', 'wisdom', 'Plat', 'um', 'we', 'aim', 'to', 'serve', 'as', 'a', 'friendly', 'vertical', 'media', '329', 'chars'], ['15', '15', '815', 'IR', 'NEXT', '16', '815', 'IR', 'NEXT', 'IR', 'AI', 'Industrial', 'XR', 'Vision', 'amp', '9', 'DoF', 'fusion', 'sensing', 'Enterprise', 'XR', '3', 'D', '4', 'VC', 'BM', 'NEXT', 'IR', '2017'], ['Platum', 'is', 'a', 'media', 'service', 'that', 'specializes', 'in', 'startups', 'and', 'its', 'motto', 'is', 'Startups', 'Story', 'PlatformPlatum', 'means', 'Space', 'for', 'sharing', 'wisdom', 'Plat', 'um', 'we', 'aim', 'to', 'serve', 'as', 'a', 'friendly', 'vertical', 'media', '329', 'chars'], ['15', 'HMG', 'Open', 'Innovation', 'Tech', 'Day', 'MOBINN', 'MobilTech', 'Metaverse', 'Entertainment', 'ViewMagine', 'Aplayz', '5', '2017', '1', '200', '1', '3', 'AI', '75', '680', 'chars'], ['XR', 'XR', 'A', 'Large', 'Space', 'WalkThrough', 'Training', 'XR', 'IR', 'Walk', 'Through', 'Locomotion', 'XR', '15', 'm', '8', 'VIP', 'M', '4', 'A', '1', 'K', '5', '10', 'VR', 'POLICE', 'ONE', '11', 'VRAR', 'XR'], ['Blockade', 'Labs', 'AI', '3', 'D', 'LDM', '3', 'DLatent', 'Diffusion', 'Model', 'for', '3', 'D', 'LDM', '3', 'D', 'depth', 'map', '360', '3', 'D', 'LMD', '3', 'D', 'AI', 'AI', 'AI', '2', 'D', '2', 'D', 'RGB', 'LDM', '3', 'D', 'LDM', '3', 'D', 'LDM', '3', 'D', '360', 'VR', 'LDM', '282', 'chars'], ['24', '14', '16', '2023', 'SK', '3', 'XR', 'AI', 'mjinews', '24', 'com'], ['24', '5', 'AI', 'AI', 'ITAI', '3', 'trueartinews', '24', 'com', '24', 'Copyrightc', 'inews', '24', 'com', 'All', 'Rights', 'ReservedPlease', 'read', 'inews', '24', 's', 'privacy', 'policy', 'Contact', '22', 'chars'], ['20230605', '161420230605', '1623'], ['IoT', '26', 'Pet', 'IoT', 'IoT', 'Pet', 'Topia', 'IoT', 'IoT', 'IoT', 'KT'], ['LG', 'AI', 'LG', 'gtLG', 'AI', 'LG', 'LG', 'AI', '25', '3', 'AI', 'AI', 'AI', 'LG', 'LG', 'AI', 'NPC', 'NPC', 'LG', 'AI', 'LG'], ['24', '12', '27', '28', '30', '12', 'AI', '300', '1', '3', 'D', '3', 'D', 'SaaS', '3', 'D', '3', 'D', '3', 'D', '3', 'D', '3', 'D', '4', '8', '12', '3', 'D', '3', 'D', 'mjinews', '24', 'com'], ['24', 'AI', '33', 'D', 'AI', '14', '6', '2023', '14', '16', '2023', 'AI', 'AI', '30', 'GPT', 'SW', 'AI', 'AI', 'AI', 'IP', 'AI', '2', 'D', '3', 'D', '3', 'D', '3', 'D', 'AI', '3', 'DGET', '3', 'D', '3', 'D', '3', 'D', 'AI', '20', '83', 'chars'], ['NHN', 'NHN', '24', 'NHN', '7', 'NHN', 'NHN', 'NHN', 'IT', 'NHN', '3', 'D', '3', 'D', 'NHN', 'NHN', 'mjinews', '24', 'com', '24', 'Copyrightc', 'inews', '24', 'com', 'All', 'Rights', 'ReservedPlease', 'read', 'inews', '24', 's', 'privacy', '39', 'chars'], ['24', '28', '30', '1', 'XR', '2', 'P', '4', '2023', 'XR', '3', 'mjinews', '24', 'com', '24', 'Copyrightc', 'inews', '24', 'com', 'All', 'Rights', 'ReservedPlease', 'read', 'inews', '24', 's', 'privacy', 'policy', 'Co', '28', 'chars'], ['24', 'LGU', 'LGU', 'LGU', '23', 'LG', '23', 'LG', 'AI', 'AI', 'LG', 'AI', 'AI', 'LGU', '23', 'AI', 'AI', 'NPC', 'LG', 'AI', 'AI', 'AI', 'AI', 'NPC', '249', 'chars'], ['24', 'NIPA', '2023', '28', '3', 'TOGATHER', 'To', 'Gather', 'Together', '50', '6', '2024', '12', '2', 'ycleverinews', '24', 'com'], ['24', '22', '100', 'feat', '20', 'CMO', 'mjinews', '24', 'com', '24', 'Copyrightc', 'inews', '24', 'com', 'All', 'Rights', 'ReservedPlease', 'read', 'inews', '24', 's', 'priv', '42', 'chars'], ['24', '8', '3', 'D', '3', 'D', 'SaaS', 'AI', '3', 'D', '3', 'D', 'mjinews', '24', 'com'], ['24', 'LG', 'Meta', 'Slap', 'LG', 'Meta', 'Slap', 'LGULG', '7', 'Meta', 'Slap', '3', 'D', '1', '500', '2', 'D', 'LG', '77', '10', '20', '9', 'LG', 'Web', '3', 'Lab', 'nocou', '18', 'chars'], ['24', 'LG', 'AI', '25', 'LG', 'AI', 'LGU', '3', 'D', 'AI', 'AI', 'AI', 'AI', 'NPC', 'AI', 'AI', 'LG', 'LG', 'LG', 'LG', 'AI', 'AI', 'LLM', 'AI', 'NPC', 'AI', 'GPT', 'AI', 'AI', 'LG', 'AI', 'AI', '200', 'LG', '3', '40', 'chars'], ['24', '4', 'NST', '4', '3', 'NST', '2014', '3040', '5080', '3', '6', 'NST', 'NST', '6', '3', '3', '1', 'PAV', 'UAM', 'LG', '19', '6', '434', 'KAIST', '10', '6', '390', '17', '69', 'chars'], ['24', '9', '9', 'AI', 'AI', 'SNS', 'nocountjuninews', '24', 'com', '24', 'Copyrightc', 'inews', '24', 'com', 'All', 'Rights', 'ReservedPlease', 'read', 'inews', '24', 's', 'privacy', 'policy', 'Contac', '24', 'chars'], ['tabletrtdtdtrtrtd', '15', 'tdtrtrtdtdtdtdtrtable', '2021', '2030', '1', '16', '20222022202420252026', '3', '48', '6', '9', '2', '857', '1', '425', '15', '93', 'chars'], ['tabletrtdtdtrtrtd', 'AR', 'tdtrtrtdtdtdtdtrtable', '2023', '5', '2500', 'CT', 'Culture', 'Technology', 'ChatGPT', 'AI', 'Generative', 'AI', '5', '224', 'chars'], ['NFT', 'NFT', 'NFT', 'PFP', 'NFT', 'NFT', 'NFT', 'Traits', 'NFT', 'NFT', 'NFT', 'NFT', 'NFT', 'UX', 'NFT', 'BAYCBored', 'Ape', 'Yacht', 'Club', 'NFT', 'NFT', 'NFT', 'S', '3044', 'chars'], ['14', '3', '2023', 'Metaverse', 'Expo', '2023', '2023', '30', 'AI', '18', '72', '1055', '19', 'Startup', 'NEST', 'UCONNECT', '2019']]\n",
      "Okt 키워드 형태소 개수: 45\n",
      "Okt 키워드 형태소: [['트레져랩스', '낫소', '와', '메타', '버스', '패션', '브랜드', '글로벌', '론칭'], ['오비', '스', '넥스트', '라이즈', '2023', '서울', '참가', '메타', '버스', '서비스', '소개'], ['메타', '캠프', '데', '어', 'there', '에서', '2023', '메타', '버스', '개발자', '경진', '대회', '개최'], ['펫', '타', '버스', 'AFWP', '로부터', '투자', '유치'], ['소울', '엑스', '2023', '싱가포르', '정보', '통신', '박람회', '참가'], ['트립', '비토', '즈', '자이언트', '스텝', '버추', '얼', '휴먼', '활용', '협업', '마케팅'], ['메타', '버스', '창작', '플랫폼', '레드브릭', '에듀', '테크', '아이스크림', '에듀', '와', 'AI', '게임', '인재', '양성', 'MOU'], ['메타', '캠프', '데', '어', '에서', '2023', '메타', '버스', '개발자', '경진', '대회', '오리엔테이션', '개최'], ['부산진', '흥원', 'XR', '메타', '버스', '8', '개', '기업', '과', '2023', '싱가포르', '정보', '통신', '전시회', '참여'], ['ZEMIVERSE', '개발', '사', '넥스', '터', '415억', '투자', '유치'], ['TG', '삼보', '디', '캐릭', '과', '메타', '버스', '사업', 'MOU', '체결'], ['원', '유니버스', '한국', '마이크로소프트', '메타', '버스', '솔루션', '기술', '협력'], ['아시아', '대표', '메타', '버스', '전시회', '2023', '메타', '버스', '엑스포', '개막', '앞둬'], ['LGU', '키즈', '토피아', '생', '성형', 'AI', '영어', '탑재', '해', '글로벌', '진출'], ['메타', '버스', '에서', '개인', '맞춤', '근', '골격계', '심리', '건강', '관리', '가능해진다'], ['틸론', 'XR', '메타', '버스', '기술', '융합', '세미나', '서', '미디어', '산업', '경쟁력', '강화', '를', '위', '한', 'XR', '메타', '버스', '의', '발전', '방향', '제시'], ['틸론', '폴리텍', '대', '와', '메타', '버스', '산업', '확산', '과', '전문', '인력', '양성', '을', '위', '한', 'MOU', '체결'], ['경기', '창조경제', '혁신', '센터', '스타트업', '815', 'IR', 'NEXT', '로', '메타', '버스', 'AI', '기업', '발굴'], ['메타', '버스', '플랫폼', '재미', '버스', '개발', '사', '넥스', '터', '415억', '원', '시드', '투자', '유치'], ['경기', '창조경제', '혁신', '센터', '투자', '유치', '지원', '프로그램', '스타트업', '815', 'IR', 'NEXT', '메타', '버스', 'AI', '스타트업', '발굴'], ['지구', '테크', '스타트업', '오후', '두시', '랩', '그린', '플로', '탄소', '중립', '생태계', '확장', '나서'], ['현대차', '그룹', '스타트업', '에', '1조', '3천억', '원', '투자', '오픈', '이노베이션', '테크', '데이', '에서', '성과', '공유'], ['스코넥', 'XR', '기반', '의', '대', '공간', '하이브리드', '형', '모의', '훈련', '시스템', '개발', '완료'], ['인텔', '랩', '텍스트', '로', '360', '도', '이미지', '생', '성', '가능한', 'AI', '확산', '모델', '공개'], ['이경일', '대표', '컴투', '버스', '인터넷', '다음', '의', '모습', '될', '것'], ['원', '유니버스', '한국', 'MS', '와', '메타', '버스', '솔루션', '기술', '협력'], ['AI', '하이테크', '시대', '메타', '버스', '전문가', '꿈', '키워요'], ['제', '이엠', '스마트', '이', '가', '펫', '코리아', '반려동물', '건강', '증진', '협력', '한다'], ['LGU', '메타', '버스', '공간', '키즈', '토피아', '에', '영어', '탑재', '세계', '로'], ['올림플래닛', '스마트', '테크', '코리아', '공식', '메타', '버스', '플랫폼', '선정'], ['메타', '버스', '생', '성형', 'AI', '만나', '활기', '인터넷', '다음', '세대', '메타', '버스', '될', '것'], ['NHN', '에듀', '유니티', '와', '교육', '메타', '버스', '플랫폼', '사업', '파트너', '십', '체결'], ['한빛소프트', '메타', '버스', '엑스포', '도쿄', '참가', 'XR', '소방', '훈련', '시스템', '소개'], ['LGU', '어린이', '부터', '직장인', '까지', '메타', '버스', '사업', '뛰어든', '이유', '는', 'IT', '돋보기'], ['카카오', '헬', '스케', '어', '개인', '맞춤', '건강', '관리', '메타', '버스', '플랫폼', '구축'], ['올림플래닛', '메타', '버스', '현직', '네트워킹', '모임', '메모', '열어'], ['올림플래닛', '임', '직원', '대상', '엘리', '펙스', '쇼케이스', '성황리', '진행'], ['LGU', '직장인', '메타', '버스', '메타', '슬랩', '체험', '단', '뽑는다'], ['생', '성형', 'AI', '탑재', '한', 'LGU', '키즈', '토피아', '글로벌', '무대', '밟는다'], ['에어', '모빌리티', '메타', '버스', '재생에너지', '디지털', '영농', '기술', '등', '4', '개', '신규', '융합', '연', '구단', '출범'], ['메타', '부사', '장', '만난', '방통위', '마약', '디지털', '범죄물', '근절', '노력', '해달라'], ['이용', '률', '낮은', '메타', '버스', '서울', '서울시', '예산', '투입', '고민'], ['경기도', '챗', 'GPTAR', '등', '문화', '기술', '콘텐츠', '유통', '자금', '지원'], ['NFT', '프로', '퍼티', '를', '설계', '하며', '생각', '해', '본', '것', '1', '사용자', '는', '프로', '퍼티', '를', '어떻게', '사용', '할까'], ['신용', '보증', '기금', '2023', '메타', '버스', '엑스포', '에서', '스타트업', '유니버스', '관', '운영']]\n"
     ]
    }
   ],
   "source": [
    "# 형태소만 저장할 리스트 생성\n",
    "okt_quotes_morphs = []\n",
    "okt_keywords_morphs = []\n",
    "\n",
    "# okt_quotes의 원소들을 반복문으로 순회\n",
    "for quote in okt_quotes:\n",
    "    # 형태소만 저장할 임시 리스트 생성\n",
    "    temp = []\n",
    "    # quote가 튜플 형태로 되어 있는 형태소와 품사 태그를 분리\n",
    "    for morph, tag in quote:\n",
    "        # 형태소만 임시 리스트에 추가\n",
    "        temp.append(morph)\n",
    "    # 임시 리스트를 okt_quotes_morphs에 추가\n",
    "    okt_quotes_morphs.append(temp)\n",
    "\n",
    "for keyword in okt_keywords:\n",
    "    # 형태소만 저장할 임시 리스트 생성\n",
    "    temp = []\n",
    "    # quote가 튜플 형태로 되어 있는 형태소와 품사 태그를 분리\n",
    "    for morph, tag in keyword:\n",
    "        # 형태소만 임시 리스트에 추가\n",
    "        temp.append(morph)\n",
    "    # 임시 리스트를 okt_quotes_morphs에 추가\n",
    "    okt_keywords_morphs.append(temp)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Okt 인용문 형태소 개수:\", len(okt_quotes_morphs))\n",
    "print(\"Okt 인용문 형태소:\", okt_quotes_morphs)\n",
    "print(\"Okt 키워드 형태소 개수:\", len(okt_keywords_morphs))\n",
    "print(\"Okt 키워드 형태소:\", okt_keywords_morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 분석을 위한 학습 데이터 불러오기\n",
    "# 학습 데이터는 네이버 영화 리뷰 데이터를 사용하였습니다.\n",
    "# 출처: https://github.com/e9t/nsmc\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"ratings_train.txt\", sep=\"\\t\")\n",
    "test_data = pd.read_csv(\"ratings_test.txt\", sep=\"\\t\")\n",
    "train_data = train_data.dropna(subset=[\"document\"]) # document 열에 결측치가 있는 행을 제거\n",
    "test_data = test_data.dropna(subset=[\"document\"])\n",
    "\n",
    "# 학습 데이터의 형태소 분석 결과를 저장할 리스트 생성\n",
    "train_okt = []\n",
    "test_okt = []\n",
    "\n",
    "# 학습 데이터에 대해 형태소 분석 수행\n",
    "for review in train_data[\"document\"]:\n",
    "    train_okt.append(okt.morphs(review))\n",
    "\n",
    "for review in test_data[\"document\"]:\n",
    "    test_okt.append(okt.morphs(review))\n",
    "\n",
    "# 형태소 분석 결과를 정수 인덱스로 변환하기 위한 사전 생성\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_okt)\n",
    "\n",
    "# 사전에 없는 단어는 0으로 처리하기 위해 인덱스를 1부터 시작하도록 설정\n",
    "tokenizer.word_index = {key: value + 1 for key, value in tokenizer.word_index.items()}\n",
    "tokenizer.word_index[\"<PAD>\"] = 0 # 패딩을 위한 특수 토큰\n",
    "\n",
    "# 형태소 분석 결과를 정수 인덱스로 변환\n",
    "train_sequences = tokenizer.texts_to_sequences(train_okt)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_okt)\n",
    "\n",
    "# 정수 인덱스로 변환된 데이터의 길이를 통일하기 위해 패딩 추가\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max_length = 30 # 최대 길이 설정\n",
    "train_padded = pad_sequences(train_sequences, padding=\"post\")\n",
    "test_padded = pad_sequences(test_sequences, padding=\"post\")\n",
    "\n",
    "# 학습 데이터의 레이블(감성)을 numpy 배열로 변환\n",
    "import numpy as np\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         10416200  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               117248    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,533,577\n",
      "Trainable params: 10,533,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 13:21:46.050487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 13:21:46.052386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 13:21:46.054210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-05 13:21:46.852021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 13:21:46.854077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 13:21:46.856695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-05 13:21:49.195733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 13:21:49.197661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 13:21:49.199808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 13:25:35.774324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 13:25:35.776355: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 13:25:35.779245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 240s 125ms/step - loss: 0.3894 - accuracy: 0.8216 - val_loss: 0.3355 - val_accuracy: 0.8531\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 242s 129ms/step - loss: 0.2424 - accuracy: 0.9030 - val_loss: 0.3624 - val_accuracy: 0.8528\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 252s 134ms/step - loss: 0.1638 - accuracy: 0.9386 - val_loss: 0.3606 - val_accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 239s 128ms/step - loss: 0.1115 - accuracy: 0.9598 - val_loss: 0.4504 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 246s 131ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.4993 - val_accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 242s 129ms/step - loss: 0.0598 - accuracy: 0.9788 - val_loss: 0.5976 - val_accuracy: 0.8437\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 236s 126ms/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 0.6224 - val_accuracy: 0.8435\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 238s 127ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.7393 - val_accuracy: 0.8455\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 236s 126ms/step - loss: 0.0314 - accuracy: 0.9885 - val_loss: 0.8298 - val_accuracy: 0.8417\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 249s 133ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.8419 - val_accuracy: 0.8377\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8707 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.870735228061676, 0.8332899808883667]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM 모델을 사용하여 감정 분석 수행\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 # 단어 사전의 크기\n",
    "embedding_dim = 100 # 임베딩 차원\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_padded, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "model.evaluate(test_padded, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:02:51.336019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 14:02:51.337892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 14:02:51.339874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:02:51.892380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 14:02:51.894479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 14:02:51.896160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# 웹3 산업 관련 인용문에 대해 감정 분석 수행\n",
    "quotes_padded = pad_sequences(tokenizer.texts_to_sequences(okt_quotes_morphs), padding=\"post\")\n",
    "quotes_pred = model.predict(quotes_padded)\n",
    "quotes_pred = np.round(quotes_pred).flatten() # 예측값을 반올림하여 0(부정) 또는 1(긍정)으로 변환\n",
    "\n",
    "# 웹3 산업 관련 키워드에 대해 감정 분석 수행\n",
    "keywords_padded = pad_sequences(tokenizer.texts_to_sequences(okt_keywords_morphs), padding=\"post\")\n",
    "keywords_pred = model.predict(keywords_padded)\n",
    "keywords_pred = np.round(keywords_pred).flatten() # 예측값을 반올림하여 0(부정) 또는 1(긍정)으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.] 18\n",
      "인용문의 감성 지수: -0.2\n",
      "키워드의 감성 지수: 0.2\n"
     ]
    }
   ],
   "source": [
    "# 인용문에 대한 감성 지수 계산\n",
    "quotes_pos = np.sum(quotes_pred == 1) # 긍정 감성 점수\n",
    "quotes_neg = np.sum(quotes_pred == 0) # 부정 감성 점수\n",
    "quotes_score = (quotes_pos - quotes_neg) / (quotes_pos + quotes_neg) # 감성 지수\n",
    "\n",
    "# 키워드에 대한 감성 지수 계산\n",
    "keywords_pos = np.sum(keywords_pred == 1) # 긍정 감성 점수\n",
    "keywords_neg = np.sum(keywords_pred == 0) # 부정 감성 점수\n",
    "keywords_score = (keywords_pos - keywords_neg) / (keywords_pos + keywords_neg) # 감성 지수\n",
    "\n",
    "# 감성 지수 출력\n",
    "print(\"인용문의 감성 지수:\", quotes_score)\n",
    "print(\"키워드의 감성 지수:\", keywords_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
